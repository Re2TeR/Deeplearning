{"cells":[{"cell_type":"markdown","metadata":{"id":"XuGhasH-hXtw"},"source":["# 인공신경망 구성하기"]},{"cell_type":"markdown","metadata":{"id":"bRlG4kkdhXt0"},"source":["## 실습 목표\n","----\n","- pytorch의 주요 기능을 이해한다.\n","- 주어진 데이터 셋을 활용하여 인공신경망을 설계한다. \n","- 인공신경망 학습 과정을 코드로 작성하고, 학습이 완료된 모델을 생성한다"]},{"cell_type":"markdown","metadata":{"id":"YM7t-76uhXt1"},"source":["## 문제 정의\n","----\n","\n","multiclass classifier"]},{"cell_type":"markdown","source":["## 주요 코드"],"metadata":{"id":"49qo7WnYu0tY"}},{"cell_type":"markdown","source":["\n","### 1. TensorDataset과 DataLoader\n","\n","- 입력 데이터를 쉽게 처리하고, 배치 단위로 잘러서 학습할 수 있게 도와주는 모듈\n","- **Dataset** : 학습시 사용하는 feature와 target의 pair로 이루어짐. \n","    - 아래에서 코드에서는 TensorDataset을 사용하여 Dataset 인스턴스를 생성했지만, 이미지의 사례와 같이 Dataset 클래스를 상속받아서 커스텀 인스턴스를 생성하는 형태로 많이 사용\n","\n","- **DataLoader**: 학습 시 각 인스턴스에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)를 생성\n","\n","![data loader](https://sebastianraschka.com/images/blog/2022/datapipes/loader-flow.png)\n","\n","\n","- **Sample code**\n","```\n","from torch.utils.data import  TensorDataset, DataLoader\n","```\n","```\n","# X,y로 분할한 데이터를 tensor로 변환\n","X_train = torch.tensor(X_train, dtype=torch.float32)\n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.int64)\n","y_test = torch.tensor(y_test, dtype=torch.int64)\n","```\n","```\n","# tensor를 TensorDataset으로 생성 - X와 y가 짝으로 이루어짐\n","train_dataset = TensorDataset(X_train, y_train)\n","test_dataset = TensorDataset(X_test, y_test)\n","```\n","```\n","# DataLoader 형태로 생성\n","train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)\n","```\n","\n","- **DataLoader가 하는 역할**\n","    - shuffling\n","    - batch ...\n","    \n","![data loader](https://sebastianraschka.com/images/blog/2022/datapipes/dataflow-good.png)\n"],"metadata":{"id":"agoI8uI4u2Tg"}},{"cell_type":"markdown","source":["\n","### 2. Device 설정\n","- 일반적으로 인공신경망의 학습은 (가능하다면) GPU를 사용하는 것이 바람직함\n","    - Colab Runtime 설정 변경\n","- GPU를 사용하여 학습을 진행하도록 명시적으로 작성 필요\n","- 연산 유형에 따라 GPU에서 수행이 불가능한 경우도 존재하는데, 그럴 경우도 마찬가지로 명시적으로 어떤 프로세서에서 연산을 수행해야하는지 코드로 작성해야함 \n","\n","```\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model = NeuralNetwork().to(device)\n","```\n"],"metadata":{"id":"r9aKhw3gzx8c"}},{"cell_type":"markdown","source":["### 3. 신경망 생성\n","\n","- **torch.nn 패키지**는 신경망 생성 및 학습 시 설정해야하는 다양한 기능을 제공\n","\n","```\n","import torch.nn as nn\n","```\n","- 신경망을 **nn.Module**을 상속받아 정의\n","    - __ __init__ __(): 신경망에서 사용할 layer를 초기화하는 부분\n","    - __forward()__: feed foward 연산 수행 시, 각 layer의 입출력이 어떻게 연결되는지를 지정\n","\n","```\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.input_layer    = nn.Linear(4, 16)\n","        self.hidden_layer1  = nn.Linear(16, 32)\n","        self.output_layer   = nn.Linear(32, 3)\n","        self.relu = nn.ReLU()\n","    \n","    def forward(self, x):\n","        out =  self.relu(self.input_layer(x))\n","        out =  self.relu(self.hidden_layer1(out))\n","        out =  self.output_layer(out)\n","        return out\n","\n","```\n"],"metadata":{"id":"mU4GSmP11aOi"}},{"cell_type":"markdown","source":["### 4. Model compile\n","\n","- 학습 시 필요한 정보들(loss function, optimizer)을 선언\n","- 일반적으로 loss와 optimizer는 아래와 같이 변수로 선언하고, 변수를 train/test 시 참고할 수 있도록 매개변수로 지정해줌 \n","\n","```\n","learning_rate = 0.01\n","loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n","```\n"],"metadata":{"id":"o47oW5LG2KvT"}},{"cell_type":"markdown","source":["### 5. Train\n","- **신경망의 학습과정**을 별도의 함수로 구성하는 것이 일반적\n","    - feed forward -> loss -> error back propagation -> (log) -> (반복)\n","\n","```\n","def train_loop(train_loader, model, loss_fn, optimizer):\n","    for batch, (X, y) in enumerate(train_loader):\n","        X, y = X.to(device), y.to(device)\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","```"],"metadata":{"id":"ZU_4khRU28kP"}},{"cell_type":"markdown","source":["### 6. Test\n","\n","- 학습과정과 비슷하나 error back propagate하는 부분이 없음\n","    - feed forward -> loss ->  (log) -> (반복)\n","\n","```\n","def test_loop(test_loader, model, loss_fn):\n","    size = len(test_loader.dataset)\n","    num_batches = len(test_loader)\n","    test_loss, correct = 0, 0\n","\n","    with torch.no_grad():\n","        for X, y in test_loader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:8f}\\n\")\n"],"metadata":{"id":"DI_l_z043pVW"}},{"cell_type":"markdown","source":["### 7. Iteration\n","- 신경망 학습은 여러 epochs을 반복해서 수행하면서 모델을 구성하는 최적의 파라미터를 찾음\n","- 지정한 epochs 수만큼 **학습**과정과 **평가**과정을 반복하면서, 모델의 성능(loss, accuracy 등)을 체크함\n","\n","```\n","epochs = 10\n","for i in range(epochs) :\n","    print(f\"Epoch {i+1} \\n------------------------\")\n","    train_loop(train_dataloader, model, loss, optimizer)\n","    test_loop(test_dataloader, model, loss)\n","print(\"Done!\")\n","```"],"metadata":{"id":"NepldSZC4SQT"}},{"cell_type":"markdown","source":["## Basic Neural Network\n","\n","iris 데이터셋을 사용하여 꽃의 품종을 구분하는 분류기를 신경망을 사용하여 구현해봅니다."],"metadata":{"id":"RdWSITNN5N55"}},{"cell_type":"markdown","source":["#### [Step1] Load libraries & Datasets"],"metadata":{"id":"_OZS5t3_5fq8"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# 데이터 불러오기\n","iris=load_iris()\n","df=pd.DataFrame(data=iris.data, columns=iris.feature_names)\n","df['label']=iris.target\n","\n","# 데이터 분할\n","y=df['label']\n","X=df.drop(['label'],axis=1)\n","X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, random_state=42, stratify=y)\n","# 각각의 품종이 동일한 비율로 들어갈 수 있게 stratify=y로 입력해주었으며 train과 test에 대한 split비율을 정하지\n","# 않았으면 default값으로 분리되어 들어가게 된다."],"metadata":{"id":"c70mBzISeYaz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### [Step2] Create DataLoader"],"metadata":{"id":"zK8W6dJw5t2j"}},{"cell_type":"code","source":["X_train=torch.tensor(X_train, dtype=torch.float32)\n","X_test=torch.tensor(X_test, dtype=torch.float32)\n","y_train=torch.tensor(y_train, dtype=torch.int64)\n","y_test=torch.tensor(y_test, dtype=torch.int64)\n","\n","train_dataset= TensorDataset(X_train, y_train)\n","test_dataset= TensorDataset(X_test, y_test)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n","test_dataloader= DataLoader(test_dataset, batch_size=10, shuffle=True)\n","# dataloader에 batchsizenum, ( X_data 10개 ,y_data 10개 )로 되어있다.\n","i=2\n","for batch, (X,y) in enumerate(train_dataloader):\n","    print(batch,(X,y))\n","    if i>2:\n","      break\n","    else:\n","      i+=1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UNrQrHZbn2fb","executionInfo":{"status":"ok","timestamp":1676426753506,"user_tz":-540,"elapsed":286,"user":{"displayName":"ter re","userId":"13421344728699485304"}},"outputId":"1ff60cd1-935d-4a8f-9187-fe159282d526"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 (tensor([[5.5000, 2.4000, 3.8000, 1.1000],\n","        [5.9000, 3.2000, 4.8000, 1.8000],\n","        [4.8000, 3.0000, 1.4000, 0.1000],\n","        [7.0000, 3.2000, 4.7000, 1.4000],\n","        [5.2000, 4.1000, 1.5000, 0.1000],\n","        [5.7000, 2.6000, 3.5000, 1.0000],\n","        [5.2000, 2.7000, 3.9000, 1.4000],\n","        [6.3000, 3.3000, 6.0000, 2.5000],\n","        [4.7000, 3.2000, 1.3000, 0.2000],\n","        [6.2000, 2.2000, 4.5000, 1.5000]]), tensor([1, 1, 0, 1, 0, 1, 1, 2, 0, 1]))\n","1 (tensor([[6.7000, 3.1000, 4.7000, 1.5000],\n","        [6.3000, 2.5000, 5.0000, 1.9000],\n","        [5.0000, 3.0000, 1.6000, 0.2000],\n","        [4.6000, 3.1000, 1.5000, 0.2000],\n","        [4.6000, 3.4000, 1.4000, 0.3000],\n","        [6.1000, 3.0000, 4.6000, 1.4000],\n","        [7.2000, 3.2000, 6.0000, 1.8000],\n","        [6.4000, 2.9000, 4.3000, 1.3000],\n","        [6.3000, 2.7000, 4.9000, 1.8000],\n","        [5.4000, 3.9000, 1.7000, 0.4000]]), tensor([1, 2, 0, 0, 0, 1, 2, 1, 2, 0]))\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-df8fd52a80b4>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train=torch.tensor(X_train, dtype=torch.float32)\n","<ipython-input-16-df8fd52a80b4>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_test=torch.tensor(X_test, dtype=torch.float32)\n","<ipython-input-16-df8fd52a80b4>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train=torch.tensor(y_train, dtype=torch.int64)\n","<ipython-input-16-df8fd52a80b4>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_test=torch.tensor(y_test, dtype=torch.int64)\n"]}]},{"cell_type":"markdown","source":["#### [Step3] Set Network Structure"],"metadata":{"id":"_0wC3m4k55xF"}},{"cell_type":"code","source":["class NNnet(nn.Module):\n","  def __init__(self):\n","    super(NNnet,self).__init__()\n","    self.input_layer=nn.Linear(4,16)\n","    self.hidden_layer1=nn.Linear(16,32)\n","    self.output_layer=nn.Linear(32,3)\n","    self.relu=nn.ReLU()\n","\n","  def forward(self,x):\n","    out=self.relu(self.input_layer(x))\n","    out=self.relu(self.hidden_layer1(out))\n","    out=self.output_layer(out)\n","    return out"],"metadata":{"id":"ns9UuH2Ko7dq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### [Step4] Create Model instance"],"metadata":{"id":"-vdPdjRF6AqV"}},{"cell_type":"code","source":["device='cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'device={device}')\n","\n","model=NNnet().to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"439rcxRepzfq","executionInfo":{"status":"ok","timestamp":1676426313316,"user_tz":-540,"elapsed":6,"user":{"displayName":"ter re","userId":"13421344728699485304"}},"outputId":"8cfc139a-6f09-46c2-a64d-71e70debe501"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["device=cpu\n"]}]},{"cell_type":"markdown","source":["#### [Step5] Model compile"],"metadata":{"id":"TtK-wiwb6Nkh"}},{"cell_type":"code","source":["# 모델 컴파일\n","# 다중 분류 문제이기 때문에 crossentropyloss를 이용한다\n","learning_rate=0.001\n","loss=nn.CrossEntropyLoss()\n","optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)"],"metadata":{"id":"kvLr5RnlqRk2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### [Step6] Set train loop"],"metadata":{"id":"FIv0Csq76YGU"}},{"cell_type":"code","source":["def train_loop(train_loader, model, loss_fn, optimizer):\n","  size= len(train_loader.dataset)\n","  \n","  for batch, (X,y) in enumerate(train_loader):\n","    X,y=X.to(device), y.to(device)\n","    pred=model(X)\n","\n","    # 손실 계산\n","    loss=loss_fn(pred,y)\n","\n","    # 역전파\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    loss, current = loss.item(), batch * len(X)\n","    print(f'loss:{loss:>7f} [{current:>5d}]/{size:5d}')"],"metadata":{"id":"P0g7kCaTqx8w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### [Step7] Set test loop"],"metadata":{"id":"uFQY-H_i6hz7"}},{"cell_type":"code","source":["def test_loop(test_loader, model, loss_fn):\n","  size=len(test_loader.dataset)\n","  num_batches=len(test_loader)\n","  test_loss, correct=0,0\n","\n","  with torch.no_grad():\n","    for X,y in test_loader:\n","      X,y = X.to(device), y.to(device)\n","      pred=model(X)\n","      test_loss += loss_fn(pred, y).item()\n","      correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n","\n","  test_loss /= num_batches\n","  correct /=size\n","  print(f'Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:8f}\\n')"],"metadata":{"id":"PbJ7DrqQtSAW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### [Step8] Run model"],"metadata":{"id":"WeM2SWZg6mr1"}},{"cell_type":"code","source":["# 모델 실행\n","epochs=10\n","\n","for i in range(epochs):\n","  print(f'Epoch{i+1}\\n----------------------')\n","  train_loop(train_dataloader, model, loss, optimizer)\n","  test_loop(test_dataloader, model, loss)\n","print('Done')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OXn3mSbnuda0","executionInfo":{"status":"ok","timestamp":1676426313733,"user_tz":-540,"elapsed":421,"user":{"displayName":"ter re","userId":"13421344728699485304"}},"outputId":"117df20f-f7a7-4716-e90d-5c22a45f8f98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch1\n","----------------------\n","loss:1.107731 [    0]/  112\n","loss:1.100865 [   10]/  112\n","loss:1.096999 [   20]/  112\n","loss:1.092211 [   30]/  112\n","loss:1.086746 [   40]/  112\n","loss:1.078221 [   50]/  112\n","loss:1.111041 [   60]/  112\n","loss:1.089211 [   70]/  112\n","loss:1.087043 [   80]/  112\n","loss:1.101246 [   90]/  112\n","loss:1.075884 [  100]/  112\n","loss:1.073514 [   22]/  112\n","Test Error: \n"," Accuracy: 65.8%, Avg loss: 1.073557\n","\n","Epoch2\n","----------------------\n","loss:1.068579 [    0]/  112\n","loss:1.050016 [   10]/  112\n","loss:1.064685 [   20]/  112\n","loss:1.053509 [   30]/  112\n","loss:1.069495 [   40]/  112\n","loss:1.071288 [   50]/  112\n","loss:1.062282 [   60]/  112\n","loss:1.046498 [   70]/  112\n","loss:1.061348 [   80]/  112\n","loss:1.069272 [   90]/  112\n","loss:1.083152 [  100]/  112\n","loss:1.024228 [   22]/  112\n","Test Error: \n"," Accuracy: 44.7%, Avg loss: 1.045456\n","\n","Epoch3\n","----------------------\n","loss:1.077618 [    0]/  112\n","loss:1.032171 [   10]/  112\n","loss:1.021152 [   20]/  112\n","loss:1.045001 [   30]/  112\n","loss:1.015447 [   40]/  112\n","loss:1.059127 [   50]/  112\n","loss:0.987152 [   60]/  112\n","loss:1.016134 [   70]/  112\n","loss:1.063953 [   80]/  112\n","loss:1.053165 [   90]/  112\n","loss:1.004180 [  100]/  112\n","loss:0.960873 [   22]/  112\n","Test Error: \n"," Accuracy: 65.8%, Avg loss: 1.015412\n","\n","Epoch4\n","----------------------\n","loss:1.049362 [    0]/  112\n","loss:1.002130 [   10]/  112\n","loss:0.986982 [   20]/  112\n","loss:0.951780 [   30]/  112\n","loss:1.006350 [   40]/  112\n","loss:1.015809 [   50]/  112\n","loss:0.998533 [   60]/  112\n","loss:0.982989 [   70]/  112\n","loss:1.018298 [   80]/  112\n","loss:0.919473 [   90]/  112\n","loss:1.034679 [  100]/  112\n","loss:1.123105 [   22]/  112\n","Test Error: \n"," Accuracy: 65.8%, Avg loss: 0.976452\n","\n","Epoch5\n","----------------------\n","loss:0.946247 [    0]/  112\n","loss:1.010187 [   10]/  112\n","loss:0.998267 [   20]/  112\n","loss:0.913072 [   30]/  112\n","loss:0.960536 [   40]/  112\n","loss:0.991468 [   50]/  112\n","loss:0.950648 [   60]/  112\n","loss:0.980705 [   70]/  112\n","loss:0.954428 [   80]/  112\n","loss:0.962877 [   90]/  112\n","loss:0.922241 [  100]/  112\n","loss:0.782455 [   22]/  112\n","Test Error: \n"," Accuracy: 65.8%, Avg loss: 0.935074\n","\n","Epoch6\n","----------------------\n","loss:1.038601 [    0]/  112\n","loss:0.911018 [   10]/  112\n","loss:0.911410 [   20]/  112\n","loss:0.946705 [   30]/  112\n","loss:0.954261 [   40]/  112\n","loss:0.873950 [   50]/  112\n","loss:0.875320 [   60]/  112\n","loss:0.925878 [   70]/  112\n","loss:0.820381 [   80]/  112\n","loss:0.812190 [   90]/  112\n","loss:0.927603 [  100]/  112\n","loss:1.027124 [   22]/  112\n","Test Error: \n"," Accuracy: 92.1%, Avg loss: 0.882523\n","\n","Epoch7\n","----------------------\n","loss:0.817679 [    0]/  112\n","loss:0.940469 [   10]/  112\n","loss:0.915048 [   20]/  112\n","loss:0.740340 [   30]/  112\n","loss:0.902599 [   40]/  112\n","loss:0.872385 [   50]/  112\n","loss:0.844114 [   60]/  112\n","loss:0.837319 [   70]/  112\n","loss:0.857887 [   80]/  112\n","loss:0.856363 [   90]/  112\n","loss:0.885375 [  100]/  112\n","loss:0.780682 [   22]/  112\n","Test Error: \n"," Accuracy: 84.2%, Avg loss: 0.830673\n","\n","Epoch8\n","----------------------\n","loss:0.760359 [    0]/  112\n","loss:0.892337 [   10]/  112\n","loss:0.708501 [   20]/  112\n","loss:0.796009 [   30]/  112\n","loss:0.704439 [   40]/  112\n","loss:0.968002 [   50]/  112\n","loss:0.801616 [   60]/  112\n","loss:0.847554 [   70]/  112\n","loss:0.862436 [   80]/  112\n","loss:0.845322 [   90]/  112\n","loss:0.651659 [  100]/  112\n","loss:0.935056 [   22]/  112\n","Test Error: \n"," Accuracy: 86.8%, Avg loss: 0.782144\n","\n","Epoch9\n","----------------------\n","loss:0.771273 [    0]/  112\n","loss:0.749077 [   10]/  112\n","loss:0.704976 [   20]/  112\n","loss:0.690632 [   30]/  112\n","loss:0.730885 [   40]/  112\n","loss:0.669943 [   50]/  112\n","loss:0.789999 [   60]/  112\n","loss:0.742286 [   70]/  112\n","loss:0.821007 [   80]/  112\n","loss:0.803873 [   90]/  112\n","loss:0.751911 [  100]/  112\n","loss:0.899447 [   22]/  112\n","Test Error: \n"," Accuracy: 81.6%, Avg loss: 0.718300\n","\n","Epoch10\n","----------------------\n","loss:0.595150 [    0]/  112\n","loss:0.686382 [   10]/  112\n","loss:0.721355 [   20]/  112\n","loss:0.725150 [   30]/  112\n","loss:0.722432 [   40]/  112\n","loss:0.743498 [   50]/  112\n","loss:0.661613 [   60]/  112\n","loss:0.636171 [   70]/  112\n","loss:0.648413 [   80]/  112\n","loss:0.669596 [   90]/  112\n","loss:0.750346 [  100]/  112\n","loss:0.859864 [   22]/  112\n","Test Error: \n"," Accuracy: 86.8%, Avg loss: 0.666081\n","\n","Done\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[{"file_id":"11TCpdcBIEU8zwY9Q05smHEHXIFaRf8XA","timestamp":1676353396738}]},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}